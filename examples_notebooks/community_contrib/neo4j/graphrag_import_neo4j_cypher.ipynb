{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fea928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bc9ba",
   "metadata": {},
   "source": [
    "# Neo4j Import of GraphRAG Result Parquet files\n",
    "\n",
    "This notebook imports the results of the GraphRAG indexing process into the Neo4j Graph database for further processing, analysis or visualization. \n",
    "\n",
    "You can also build your own GenAI applications using Neo4j and a number of RAG strategies with LangChain, LlamaIndex, Haystack, and many other frameworks.\n",
    "See: https://neo4j.com/labs/genai-ecosystem\n",
    "\n",
    "Here is what the end result looks like:\n",
    "\n",
    "![](https://dev.assets.neo4j.com/wp-content/uploads/graphrag-neo4j-visualization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924e246",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "\n",
    "The notebook loads the parquet files from the `output` folder of your indexing process and loads them into Pandas dataframes.\n",
    "It then uses a batching approach to send a slice of the data into Neo4j to create nodes and relationships and add relevant properties. The id-arrays on most entities are turned into relationships. \n",
    "\n",
    "All operations use MERGE, so they are idempotent, and you can run the script multiple times.\n",
    "\n",
    "If you need to clean out the database, you can run the following statement\n",
    "\n",
    "```cypher\n",
    "MATCH (n)\n",
    "CALL { WITH n DETACH DELETE n } IN TRANSACTIONS OF 25000 ROWS;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adca1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHRAG_FOLDER = fr\"D:\\pyprojects\\graphrag_project_test\\output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "### Depedendencies\n",
    "\n",
    "We only need Pandas and the neo4j Python driver with the rust extension for faster network transport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b57beec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet pandas neo4j-rust-ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3eeee95f-e4f2-4052-94fb-a5dc8ab542ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307dd2f4",
   "metadata": {},
   "source": [
    "## Neo4j Installation\n",
    "\n",
    "You can create a free instance of Neo4j [online](https://console.neo4j.io). You get a credentials file that you can use for the connection credentials. You can also get an instance in any of the cloud marketplaces.\n",
    "\n",
    "If you want to install Neo4j locally either use [Neo4j Desktop](https://neo4j.com/download) or \n",
    "the official Docker image: `docker run -e NEO4J_AUTH=neo4j/password -p 7687:7687 -p 7474:7474 neo4j` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6c15443-4acb-4f91-88ea-4e08abaa4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "NEO4J_URI = \"neo4j://10.1.150.105:7687\"  # or neo4j+s://xxxx.databases.neo4j.io\n",
    "# NEO4J_URI = \"bolt://10.1.150.105:7687\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"neo4jneo4j\"  # your password\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] =  NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"] = NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"] = NEO4J_PASSWORD\n",
    "\n",
    "# Create a Neo4j driver\n",
    "auth= (NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=auth,trust='TRUST_ALL_CERTIFICATES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b278335e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.verify_authentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c88251a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f37ab6",
   "metadata": {},
   "source": [
    "## Batched Import\n",
    "\n",
    "The batched import function takes a Cypher insert statement (needs to use the variable `value` for the row) and a dataframe to import.\n",
    "It will send by default 1k rows at a time as query parameter to the database to be inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d787bf7b-ac9b-4bfb-b140-a50a3fd205c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_import(statement, df, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Import a dataframe into Neo4j using a batched approach.\n",
    "    Parameters: statement is the Cypher query to execute, df is the dataframe to import, and batch_size is the number of rows to import in each batch.\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    start_s = time.time()\n",
    "    for start in range(0, total, batch_size):\n",
    "        batch = df.iloc[start : min(start + batch_size, total)]\n",
    "        result = driver.execute_query(\n",
    "            \"UNWIND $rows AS value \" + statement,\n",
    "            rows=batch.to_dict(\"records\"),\n",
    "            database_=NEO4J_DATABASE,\n",
    "        )\n",
    "        print(result.summary.counters)\n",
    "    print(f\"{total} rows in {time.time() - start_s} s.\")\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb45f42",
   "metadata": {},
   "source": [
    "## Indexes and Constraints\n",
    "\n",
    "Indexes in Neo4j are only used to find the starting points for graph queries, e.g. quickly finding two nodes to connect.\n",
    "Constraints exist to avoid duplicates, we create them mostly on id's of Entity types.\n",
    "\n",
    "We use some Types as markers with two underscores before and after to distinguish them from the actual entity types.\n",
    "\n",
    "The default relationship type here is `RELATED` but we could also infer a real relationship-type from the description or the types of the start and end-nodes.\n",
    "\n",
    "* `__Entity__`\n",
    "* `__Document__`\n",
    "* `__Chunk__`\n",
    "* `__Community__`\n",
    "* `__Covariate__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed7f212e-9148-424c-adc6-d81db9f8e5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique\n",
      "\n",
      "create constraint document_id if not exists for (d:__Document__) require d.id is unique\n",
      "\n",
      "create constraint entity_id if not exists for (c:__Community__) require c.community is unique\n",
      "\n",
      "create constraint entity_id if not exists for (e:__Entity__) require e.id is unique\n",
      "\n",
      "create constraint entity_title if not exists for (e:__Entity__) require e.name is unique\n",
      "\n",
      "create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique\n",
      "\n",
      "create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique\n"
     ]
    }
   ],
   "source": [
    "# create constraints, idempotent operation\n",
    "\n",
    "statements = [\n",
    "    \"\\ncreate constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique\",\n",
    "    \"\\ncreate constraint document_id if not exists for (d:__Document__) require d.id is unique\",\n",
    "    \"\\ncreate constraint entity_id if not exists for (c:__Community__) require c.community is unique\",\n",
    "    \"\\ncreate constraint entity_id if not exists for (e:__Entity__) require e.id is unique\",\n",
    "    \"\\ncreate constraint entity_title if not exists for (e:__Entity__) require e.name is unique\",\n",
    "    \"\\ncreate constraint entity_title if not exists for (e:__Covariate__) require e.title is unique\",\n",
    "    \"\\ncreate constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique\",\n",
    "    \"\\n\",\n",
    "]\n",
    "\n",
    "for statement in statements:\n",
    "    if len((statement or \"\").strip()) > 0:\n",
    "        print(statement)\n",
    "        driver.execute_query(statement) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea073b",
   "metadata": {},
   "source": [
    "## Import Process\n",
    "\n",
    "### Importing the Documents\n",
    "\n",
    "We're loading the parquet file for the documents and create nodes with their ids and add the title property.\n",
    "We don't need to store text_unit_ids as we can create the relationships and the text content is also contained in the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1ba023e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d70e9dcac2eabfc37406708b689553bf882f54625a5e7...</td>\n",
       "      <td>1</td>\n",
       "      <td>A方案.txt</td>\n",
       "      <td>&lt;标题目录toc：A方案.docx|产品技术资料|项目名称/&gt;寿县迎河镇中心卫生院信息化系统...</td>\n",
       "      <td>[8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ee19383b6b563f2fa20b2321b9d5467299e1fd13f9d2f...</td>\n",
       "      <td>2</td>\n",
       "      <td>b.txt</td>\n",
       "      <td>智慧医院 智慧医疗 智慧服务 智慧管理 云计算 电子病历系统应用分级 医院智慧服务分级评估标...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  human_readable_id  \\\n",
       "0  5d70e9dcac2eabfc37406708b689553bf882f54625a5e7...                  1   \n",
       "1  1ee19383b6b563f2fa20b2321b9d5467299e1fd13f9d2f...                  2   \n",
       "\n",
       "     title                                               text  \\\n",
       "0  A方案.txt  <标题目录toc：A方案.docx|产品技术资料|项目名称/>寿县迎河镇中心卫生院信息化系统...   \n",
       "1    b.txt  智慧医院 智慧医疗 智慧服务 智慧管理 云计算 电子病历系统应用分级 医院智慧服务分级评估标...   \n",
       "\n",
       "                                       text_unit_ids  \n",
       "0  [8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...  \n",
       "1                                               None  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_documents.parquet\")\n",
    "doc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f531050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'human_readable_id', 'title', 'text', 'text_unit_ids'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1354513c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;标题目录toc：A方案.docx|产品技术资料|项目名称/&gt;寿县迎河镇中心卫生院信息化系统...</td>\n",
       "      <td>[8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>智慧医院 智慧医疗 智慧服务 智慧管理 云计算 电子病历系统应用分级 医院智慧服务分级评估标...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  <标题目录toc：A方案.docx|产品技术资料|项目名称/>寿县迎河镇中心卫生院信息化系统...   \n",
       "1  智慧医院 智慧医疗 智慧服务 智慧管理 云计算 电子病历系统应用分级 医院智慧服务分级评估标...   \n",
       "\n",
       "                                       text_unit_ids  \n",
       "0  [8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...  \n",
       "1                                               None  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df_text = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_documents.parquet\", columns=['text', 'text_unit_ids'])\n",
    "doc_df_text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d522b4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_df_text['text_unit_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "02f7ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8c64040315c1f54b4e224d6f97dd4b383b46f277f21737adc768145ff6143abc180f9d0d64f1049709cd04c1704fd3d0b42e39ad60ff88ba017579a8aba51bc3\n",
      "c51e99bd9fc2024ee3c3932495a421c27a3740f403077fb25b9a9124ddc6b9dc41785b78e75958d49ad56dfbed4c229681ebbdd801b6abf90aa726d0f310cc52\n",
      "395093caa7b296f0b04e35c4ff56eebdcc10a4bf1d9263309e62fb36f646908ffe030b23992fa75b26b693e1026a0c911aa15a68149f39742d603267f749c756\n",
      "4ef34c4b1ab47439e911a1806feaab17f81b8c2d53c834ceb41c2f7308d8aa81012f86dedc85b6f26082e77b64ffd7c22ff73ad544f552d9790d6a3c479b7ebb\n",
      "5c1484ac2a3d1a443e8f252d978114193cb25402982409f16542c2717acccdef5c3823c474c5154fc9a193bfd3ce846f6c73c9a818888ae970fe696d9a86bfeb\n",
      "0f643ad2c6981c55685a607b481f657b850ab2def852349b22dd5e2525cc5519b0d866e62af43c7e658410dc84ac3a28f7c63a0a28c18cc9652971664cb7e030\n",
      "f6afb740e666cfe9fa32f7967878ec20efbeff4140cea0c9429ebc226ddc21bc42fb92d1c85c9f95c2760e1db0494f5a88ce8bf26f82fddcccfd9715e0e63e9f\n",
      "5bfd8c44ad20779f43fabfa7fe5ab76461e277eb2c4f4939ec282a2772af7a763372b0d9a9a85cf3c3318b5a9d24161e8b1ab2b2d99ee2991ea60d08d689d4e1\n",
      "f02eb32b00ece255853b57de1126839dd216afd8075d0162557533af7ee4128994cd5689b14ae36517a38908b2018f0f1e355f29ef8ba8140a738716fac1a687\n",
      "258bbe7fba65a1fb3609d114f49206773eb1ca5690074e210e24cef39f74ee52dbd5aa43db5a11f959a5fbfa8df129f83f47c694b287d079b9568bc86a60fb5f\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(doc_df_text['text_unit_ids'][0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "96391c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 2, 'nodes_created': 2, 'properties_set': 4}\n",
      "2 rows in 0.0472722053527832 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import documents\n",
    "statement = \"\"\"\n",
    "MERGE (d:__Document__ {id:value.id})\n",
    "SET d += value {.title}\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, doc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97bbadb",
   "metadata": {},
   "source": [
    "### Loading Text Units\n",
    "\n",
    "We load the text units, create a node per id and set the text and number of tokens.\n",
    "Then we connect them to the documents that we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d825626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>document_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8c64040315c1f54b4e224d6f97dd4b383b46f277f21737...</td>\n",
       "      <td>&lt;标题目录toc：A方案.docx|产品技术资料|项目名称/&gt;寿县迎河镇中心卫生院信息化系统...</td>\n",
       "      <td>870</td>\n",
       "      <td>[5d70e9dcac2eabfc37406708b689553bf882f54625a5e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c51e99bd9fc2024ee3c3932495a421c27a3740f403077f...</td>\n",
       "      <td>&lt;标题目录toc：A方案.docx|产品技术资料|建设背景/&gt;在深化医改的大背景下，国家高度...</td>\n",
       "      <td>828</td>\n",
       "      <td>[5d70e9dcac2eabfc37406708b689553bf882f54625a5e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  8c64040315c1f54b4e224d6f97dd4b383b46f277f21737...   \n",
       "1  c51e99bd9fc2024ee3c3932495a421c27a3740f403077f...   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  <标题目录toc：A方案.docx|产品技术资料|项目名称/>寿县迎河镇中心卫生院信息化系统...       870   \n",
       "1  <标题目录toc：A方案.docx|产品技术资料|建设背景/>在深化医改的大背景下，国家高度...       828   \n",
       "\n",
       "                                        document_ids  \n",
       "0  [5d70e9dcac2eabfc37406708b689553bf882f54625a5e...  \n",
       "1  [5d70e9dcac2eabfc37406708b689553bf882f54625a5e...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_text_units.parquet\",\n",
    "    columns=[\"id\", \"text\", \"n_tokens\", \"document_ids\"],\n",
    ")\n",
    "text_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffd3d380-8710-46f5-b90a-04ed8482192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 144, 'relationships_created': 144, 'nodes_created': 144, 'properties_set': 432}\n",
      "144 rows in 0.2184913158416748 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"\n",
    "MERGE (c:__Chunk__ {id:value.id})\n",
    "SET c += value {.text, .n_tokens}\n",
    "WITH c, value\n",
    "UNWIND value.document_ids AS document\n",
    "MATCH (d:__Document__ {id:document})\n",
    "MERGE (c)-[:PART_OF]->(d)\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b2094",
   "metadata": {},
   "source": [
    "### Loading Nodes\n",
    "\n",
    "For the nodes we store id, name, description, embedding (if available), human readable id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9b3f4727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\pyprojects\\\\graphrag_project_test\\\\output'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRAPHRAG_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2392f9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e88c80ef-f199-463f-a8c0-c9582bb48fb9</td>\n",
       "      <td>0</td>\n",
       "      <td>寿县迎河镇中心卫生院信息化系统建设提升项目</td>\n",
       "      <td>项目名称</td>\n",
       "      <td>该项目旨在提升寿县迎河镇中心卫生院的信息化水平，优化和整合医院内外相关的资源，构建信息化的顶...</td>\n",
       "      <td>[8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d56f96eb-034a-4227-953b-a218d1388241</td>\n",
       "      <td>1</td>\n",
       "      <td>公立医院</td>\n",
       "      <td>组织架构</td>\n",
       "      <td>公立医院作为我国医疗机构服务体系中覆盖范围最广、数量最大、服务患者最多的医疗机构，是整个医改...</td>\n",
       "      <td>[8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  human_readable_id  \\\n",
       "0  e88c80ef-f199-463f-a8c0-c9582bb48fb9                  0   \n",
       "1  d56f96eb-034a-4227-953b-a218d1388241                  1   \n",
       "\n",
       "                   title  type  \\\n",
       "0  寿县迎河镇中心卫生院信息化系统建设提升项目  项目名称   \n",
       "1                   公立医院  组织架构   \n",
       "\n",
       "                                         description  \\\n",
       "0  该项目旨在提升寿县迎河镇中心卫生院的信息化水平，优化和整合医院内外相关的资源，构建信息化的顶...   \n",
       "1  公立医院作为我国医疗机构服务体系中覆盖范围最广、数量最大、服务患者最多的医疗机构，是整个医改...   \n",
       "\n",
       "                                       text_unit_ids  \n",
       "0  [8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...  \n",
       "1  [8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_entities.parquet\",\n",
    "    # columns=[\n",
    "    #     \"name\",\n",
    "    #     \"type\",\n",
    "    #     \"description\",\n",
    "    #     \"human_readable_id\",\n",
    "    #     # \"id\",\n",
    "    #     \"description_embedding\",\n",
    "    #     \"text_unit_ids\",\n",
    "    # ],\n",
    ")\n",
    "entity_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "baf230e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'human_readable_id', 'title', 'type', 'description',\n",
       "       'text_unit_ids'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "401b0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c80e5d0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m entity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGRAPHRAG_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/create_final_entities.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     ],\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m entity_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mentity_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mGRAPHRAG_FOLDER\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/entity_df.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pyprojects\\graphrag\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pyprojects\\graphrag\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2407\u001b[0m     df,\n\u001b[0;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[1;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pyprojects\\graphrag\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\pyprojects\\graphrag\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:57\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     46\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m WriteExcelBuffer \u001b[38;5;241m|\u001b[39m ExcelWriter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m     engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     62\u001b[0m         path,\n\u001b[0;32m     63\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m     67\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_entities.parquet\",\n",
    "    columns=[\n",
    "        \"title\",\n",
    "        \"type\",\n",
    "        \"description\",\n",
    "        \"text_unit_ids\",\n",
    "    ],\n",
    ")\n",
    "entity_df.head(2)\n",
    "entity_df.to_excel(f\"{GRAPHRAG_FOLDER}/entity_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d038114-0714-48ee-a48a-c421cd539661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 1000, 'relationships_created': 1496, 'nodes_created': 1000, 'properties_set': 4000}\n",
      "{'_contains_updates': True, 'labels_added': 98, 'relationships_created': 102, 'nodes_created': 98, 'properties_set': 392}\n",
      "1098 rows in 0.7353570461273193 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_statement = \"\"\"\n",
    "MERGE (e:__Entity__ {id:value.id})\n",
    "SET e += value {.human_readable_id, .description, name:replace(value.name,'\"','')}\n",
    "WITH e, value\n",
    "# CALL db.create.setNodeVectorProperty(e, \"description_embedding\", value.description_embedding)\n",
    "CALL apoc.create.addLabels(e, case when coalesce(value.type,\"\") = \"\" then [] else [apoc.text.upperCamelCase(replace(value.type,'\"',''))] end) yield node\n",
    "UNWIND value.text_unit_ids AS text_unit\n",
    "MATCH (c:__Chunk__ {id:text_unit})\n",
    "MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "\"\"\"\n",
    "\n",
    "entity_statement = \"\"\"\n",
    "MERGE (e:__Entity__ {id:value.id})\n",
    "SET e += value {.human_readable_id, .description, name:replace(value.name,'\"','')}\n",
    "WITH e, value\n",
    "CALL apoc.create.addLabels(e, case when coalesce(value.type,\"\") = \"\" then [] else [apoc.text.upperCamelCase(replace(value.type,'\"',''))] end) yield node\n",
    "UNWIND value.text_unit_ids AS text_unit\n",
    "MATCH (c:__Chunk__ {id:text_unit})\n",
    "MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "\"\"\"\n",
    "\n",
    "batched_import(entity_statement, entity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d4f87",
   "metadata": {},
   "source": [
    "### Import Relationships\n",
    "\n",
    "For the relationships we find the source and target node by name, using the base `__Entity__` type.\n",
    "After creating the `RELATED` relationships, we set the description as attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b347a047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "      <th>combined_degree</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b9c99913-ede4-4471-89f7-3f9223110376</td>\n",
       "      <td>0</td>\n",
       "      <td>寿县迎河镇中心卫生院信息化系统建设提升项目</td>\n",
       "      <td>公立医院</td>\n",
       "      <td>该项目旨在提升寿县迎河镇中心卫生院的信息化水平，优化和整合医院内外相关的资源，构建信息化的顶...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602cbf75-1b27-4c1e-8f07-dd99f4153141</td>\n",
       "      <td>1</td>\n",
       "      <td>信息化建设</td>\n",
       "      <td>医院信息化建设</td>\n",
       "      <td>信息化建设是公立医院在服务患者、诊断治疗和运营管理过程中的最得力和最有效的支撑手段和工具，医...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  human_readable_id  \\\n",
       "0  b9c99913-ede4-4471-89f7-3f9223110376                  0   \n",
       "1  602cbf75-1b27-4c1e-8f07-dd99f4153141                  1   \n",
       "\n",
       "                  source   target  \\\n",
       "0  寿县迎河镇中心卫生院信息化系统建设提升项目     公立医院   \n",
       "1                  信息化建设  医院信息化建设   \n",
       "\n",
       "                                         description  weight  combined_degree  \\\n",
       "0  该项目旨在提升寿县迎河镇中心卫生院的信息化水平，优化和整合医院内外相关的资源，构建信息化的顶...    16.0                2   \n",
       "1  信息化建设是公立医院在服务患者、诊断治疗和运营管理过程中的最得力和最有效的支撑手段和工具，医...    18.0                3   \n",
       "\n",
       "                                       text_unit_ids  \n",
       "0  [8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...  \n",
       "1  [8c64040315c1f54b4e224d6f97dd4b383b46f277f2173...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_relationships.parquet\",\n",
    "    # columns=[\n",
    "    #     \"source\",\n",
    "    #     \"target\",\n",
    "    #     \"id\",\n",
    "    #     \"rank\",\n",
    "    #     \"weight\",\n",
    "    #     \"human_readable_id\",\n",
    "    #     \"description\",\n",
    "    #     \"text_unit_ids\",\n",
    "    # ],\n",
    ")\n",
    "rel_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27900c01-89e1-4dec-9d5c-c07317c68baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "1603 rows in 0.26153564453125 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1603"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_statement = \"\"\"\n",
    "    MATCH (source:__Entity__ {name:replace(value.source,'\"','')})\n",
    "    MATCH (target:__Entity__ {name:replace(value.target,'\"','')})\n",
    "    // not necessary to merge on id as there is only one relationship per pair\n",
    "    MERGE (source)-[rel:RELATED {id: value.id}]->(target)\n",
    "    SET rel += value {.rank, .weight, .human_readable_id, .description, .text_unit_ids}\n",
    "    RETURN count(*) as createdRels\n",
    "\"\"\"\n",
    "\n",
    "batched_import(rel_statement, rel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6365dd7",
   "metadata": {},
   "source": [
    "### Importing Communities\n",
    "\n",
    "For communities we import their id, title, level.\n",
    "We connect the `__Community__` nodes to the start and end nodes of the relationships they refer to.\n",
    "\n",
    "Connecting them to the chunks they orignate from is optional, as the entites are already connected to the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2fab66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>relationship_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>075831db-80f3-4618-beab-221cacabd5b9</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 0</td>\n",
       "      <td>[08d3ab7df077fa8adb73252e187418baf561c3fa5d5bf...</td>\n",
       "      <td>[0943abcb-644c-4615-9f3f-65b75d5c5f3a, 0b3874e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9f84503f-8143-443d-b77d-eba2defc61dc</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 1</td>\n",
       "      <td>[0d59581bb7b2e2b24b5457b251445ee6a7d75f577c3b7...</td>\n",
       "      <td>[03b935bb-844b-4968-9ebb-e6f6422a7b0b, 05aa626...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  level        title  \\\n",
       "0  075831db-80f3-4618-beab-221cacabd5b9      0  Community 0   \n",
       "1  9f84503f-8143-443d-b77d-eba2defc61dc      0  Community 1   \n",
       "\n",
       "                                       text_unit_ids  \\\n",
       "0  [08d3ab7df077fa8adb73252e187418baf561c3fa5d5bf...   \n",
       "1  [0d59581bb7b2e2b24b5457b251445ee6a7d75f577c3b7...   \n",
       "\n",
       "                                    relationship_ids  \n",
       "0  [0943abcb-644c-4615-9f3f-65b75d5c5f3a, 0b3874e...  \n",
       "1  [03b935bb-844b-4968-9ebb-e6f6422a7b0b, 05aa626...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_communities.parquet\",\n",
    "    columns=[\"id\", \"level\", \"title\", \"text_unit_ids\", \"relationship_ids\"],\n",
    ")\n",
    "\n",
    "community_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1351f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 186, 'nodes_created': 186, 'properties_set': 558}\n",
      "186 rows in 0.20482611656188965 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"\n",
    "MERGE (c:__Community__ {community:value.id})\n",
    "SET c += value {.level, .title}\n",
    "/*\n",
    "UNWIND value.text_unit_ids as text_unit_id\n",
    "MATCH (t:__Chunk__ {id:text_unit_id})\n",
    "MERGE (c)-[:HAS_CHUNK]->(t)\n",
    "WITH distinct c, value\n",
    "*/\n",
    "WITH *\n",
    "UNWIND value.relationship_ids as rel_id\n",
    "MATCH (start:__Entity__)-[:RELATED {id:rel_id}]->(end:__Entity__)\n",
    "MERGE (start)-[:IN_COMMUNITY]->(c)\n",
    "MERGE (end)-[:IN_COMMUNITY]->(c)\n",
    "RETURn count(distinct c) as createdCommunities\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, community_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9adf50",
   "metadata": {},
   "source": [
    "### Importing Community Reports\n",
    "\n",
    "Fo the community reports we create nodes for each communitiy set the id, community, level, title, summary, rank, and rank_explanation and connect them to the entities they are about.\n",
    "For the findings we create the findings in context of the communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1be9e7a9-69ee-406b-bce5-95a9c41ecffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>community</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>full_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9d50fe10734840ae988e63b9542f869f</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>智慧医院信息系统管理标准</td>\n",
       "      <td>该社区主要围绕智慧医院信息系统的管理标准展开，涵盖了从项目组织、管理、实施、进度、风险保障、...</td>\n",
       "      <td>[{'explanation': '管理标准是智慧医院信息系统的重要组成部分，旨在确保医院信...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>该报告对智慧医院信息系统的管理标准进行了全面深入的分析，对理解并实施全面的医疗信息系统的标准...</td>\n",
       "      <td># 智慧医院信息系统管理标准\\n\\n该社区主要围绕智慧医院信息系统的管理标准展开，涵盖了从项...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9bd70d796f449f1a50f84579173cf87</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>数据修改全程监控与数据库访问的安全性控制</td>\n",
       "      <td>该社区主要围绕数据修改全程监控和数据库访问的安全性控制两个核心功能展开。这两个功能通过确保数...</td>\n",
       "      <td>[{'explanation': '数据修改全程监控功能提供数据修改的全程监控，确保数据修改...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>该社区在医疗信息系统的标准规范、功能模块和系统集成方面具有高度相关性和重要性，对提升医院运营...</td>\n",
       "      <td># 数据修改全程监控与数据库访问的安全性控制\\n\\n该社区主要围绕数据修改全程监控和数据库访...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  community  level                 title  \\\n",
       "0  9d50fe10734840ae988e63b9542f869f        178      3          智慧医院信息系统管理标准   \n",
       "1  a9bd70d796f449f1a50f84579173cf87        179      3  数据修改全程监控与数据库访问的安全性控制   \n",
       "\n",
       "                                             summary  \\\n",
       "0  该社区主要围绕智慧医院信息系统的管理标准展开，涵盖了从项目组织、管理、实施、进度、风险保障、...   \n",
       "1  该社区主要围绕数据修改全程监控和数据库访问的安全性控制两个核心功能展开。这两个功能通过确保数...   \n",
       "\n",
       "                                            findings  rank  \\\n",
       "0  [{'explanation': '管理标准是智慧医院信息系统的重要组成部分，旨在确保医院信...   9.5   \n",
       "1  [{'explanation': '数据修改全程监控功能提供数据修改的全程监控，确保数据修改...   8.5   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  该报告对智慧医院信息系统的管理标准进行了全面深入的分析，对理解并实施全面的医疗信息系统的标准...   \n",
       "1  该社区在医疗信息系统的标准规范、功能模块和系统集成方面具有高度相关性和重要性，对提升医院运营...   \n",
       "\n",
       "                                        full_content  \n",
       "0  # 智慧医院信息系统管理标准\\n\\n该社区主要围绕智慧医院信息系统的管理标准展开，涵盖了从项...  \n",
       "1  # 数据修改全程监控与数据库访问的安全性控制\\n\\n该社区主要围绕数据修改全程监控和数据库访...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_report_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_community_reports.parquet\",\n",
    "    columns=[\n",
    "        \"id\",\n",
    "        \"community\",\n",
    "        \"level\",\n",
    "        \"title\",\n",
    "        \"summary\",\n",
    "        \"findings\",\n",
    "        \"rank\",\n",
    "        \"rank_explanation\",\n",
    "        \"full_content\",\n",
    "    ],\n",
    ")\n",
    "community_report_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c6ed591-f98c-4403-9fde-8d4cb4c01cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 1328, 'relationships_created': 1142, 'nodes_created': 1328, 'properties_set': 4728}\n",
      "186 rows in 0.3421504497528076 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import communities\n",
    "community_statement = \"\"\"\n",
    "MERGE (c:__Community__ {community:value.community})\n",
    "SET c += value {.level, .title, .rank, .rank_explanation, .full_content, .summary}\n",
    "WITH c, value\n",
    "UNWIND range(0, size(value.findings)-1) AS finding_idx\n",
    "WITH c, value, finding_idx, value.findings[finding_idx] as finding\n",
    "MERGE (c)-[:HAS_FINDING]->(f:Finding {id:finding_idx})\n",
    "SET f += finding\n",
    "\"\"\"\n",
    "batched_import(community_statement, community_report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1a24a",
   "metadata": {},
   "source": [
    "### Importing Covariates\n",
    "\n",
    "Covariates are for instance claims on entities, we connect them to the chunks where they originate from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523bed92-d12c-4fc4-aa44-6c62321b36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cov_df = (pd.read_parquet(f\"{GRAPHRAG_FOLDER}/create_final_covariates.parquet\"),)\n",
    "# #                         columns=[\"id\",\"text_unit_id\"])\n",
    "# cov_df.head(2)\n",
    "# # Subject id do not match entity ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e064234-5fce-448e-8bb4-ab2f35699049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import covariates\n",
    "cov_statement = \"\"\"\n",
    "MERGE (c:__Covariate__ {id:value.id})\n",
    "SET c += apoc.map.clean(value, [\"text_unit_id\", \"document_ids\", \"n_tokens\"], [NULL, \"\"])\n",
    "WITH c, value\n",
    "MATCH (ch:__Chunk__ {id: value.text_unit_id})\n",
    "MERGE (ch)-[:HAS_COVARIATE]->(c)\n",
    "\"\"\"\n",
    "batched_import(cov_statement, cov_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00340bae",
   "metadata": {},
   "source": [
    "### Visualize your data\n",
    "\n",
    "You can now [Open] Neo4j on Aura, you need to log in with either SSO or your credentials.\n",
    "\n",
    "Or open https://workspace-preview.neo4j.io and connect to your local instance, remember the URI is `neo4j://localhost` and `neo4j` as username and `password` as password.\n",
    "\n",
    "In \"Explore\" you can explore by using visual graph patterns and then explore and expand further.\n",
    "\n",
    "In \"Query\", you can open the left sidebar and explore by clicking on the nodes and relationships.\n",
    "You can also use the co-pilot to generate Cypher queries for your, here are some examples.\n",
    "\n",
    "#### Show a few `__Entity__` nodes and their relationships (Entity Graph)\n",
    "\n",
    "```cypher\n",
    "MATCH path = (:__Entity__)-[:RELATED]->(:__Entity__)\n",
    "RETURN path LIMIT 200\n",
    "```\n",
    "\n",
    "#### Show the Chunks and the Document (Lexical Graph)\n",
    "\n",
    "```cypher\n",
    "MATCH (d:__Document__) WITH d LIMIT 1\n",
    "MATCH path = (d)<-[:PART_OF]-(c:__Chunk__)\n",
    "RETURN path LIMIT 100\n",
    "```\n",
    "\n",
    "####  Show a Community and it's Entities\n",
    "\n",
    "```cypher\n",
    "MATCH (c:__Community__) WITH c LIMIT 1\n",
    "MATCH path = (c)<-[:IN_COMMUNITY]-()-[:RELATED]-(:__Entity__)\n",
    "RETURN path LIMIT 100\n",
    "```\n",
    "\n",
    "#### Show everything\n",
    "\n",
    "```cypher\n",
    "MATCH (d:__Document__) WITH d LIMIT 1\n",
    "MATCH path = (d)<-[:PART_OF]-(:__Chunk__)-[:HAS_ENTIY]->()-[:RELATED]-()-[:IN_COMMUNITY]->()\n",
    "RETURN path LIMIT 250\n",
    "```\n",
    "\n",
    "We showed the visualization of this last query at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa8529",
   "metadata": {},
   "source": [
    "If you have questions, feel free to reach out in the GraphRAG discord server: \n",
    "https://discord.gg/graphrag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
